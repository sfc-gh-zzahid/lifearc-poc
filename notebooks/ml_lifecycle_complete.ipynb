{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# LifeArc ML Pipeline - Complete Lifecycle in Snowflake\n",
    "\n",
    "## End-to-End Machine Learning for Drug Discovery\n",
    "\n",
    "This notebook demonstrates **production-grade ML workflows** using native Snowflake ML capabilities:\n",
    "\n",
    "| Stage | Snowflake Capability | Why It Matters |\n",
    "|-------|---------------------|----------------|\n",
    "| 1. Discovery | Snowpark DataFrames | Scalable EDA on large datasets |\n",
    "| 2. Feature Engineering | **Snowflake Feature Store** | Centralized, versioned, point-in-time correct |\n",
    "| 3. Training | **Experiments** | Track runs, compare hyperparameters |\n",
    "| 4. Registry | **Snowflake Model Registry** | Version control, aliases, lifecycle |\n",
    "| 5. Deployment | Model Serving | Inference at scale |\n",
    "| 6. Monitoring | **ML Observability** | Drift detection, alerting |\n",
    "| 7. Lineage | **ML Lineage** | End-to-end traceability for compliance |\n",
    "\n",
    "### Use Case: Clinical Trial Outcome Prediction\n",
    "\n",
    "Predict patient response category (Complete Response, Partial Response, Stable Disease, Progressive Disease) based on:\n",
    "- Biomarker status\n",
    "- Treatment arm\n",
    "- Trial phase\n",
    "- Target gene\n",
    "- ctDNA confirmation\n",
    "\n",
    "**Business Value**: Patient stratification for trial enrollment optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Environment Setup & Connection\n",
    "\n",
    "Connect to Snowflake and import native ML libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:43.893227Z",
     "iopub.status.busy": "2026-01-20T00:17:43.893132Z",
     "iopub.status.idle": "2026-01-20T00:17:48.220903Z",
     "shell.execute_reply": "2026-01-20T00:17:48.220576Z"
    }
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "To use the modeling library, install scikit-learn version >= 1.4 and < 1.8",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msnowflake\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_store\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     FeatureStore, \n\u001b[32m     13\u001b[39m     Entity, \n\u001b[32m     14\u001b[39m     FeatureView,\n\u001b[32m     15\u001b[39m     CreationMode\n\u001b[32m     16\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msnowflake\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Registry\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msnowflake\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder, StandardScaler\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msnowflake\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msnowflake\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/snowflake/ml/modeling/preprocessing/__init__.py:7\u001b[39m\n\u001b[32m      5\u001b[39m pkg_dir = os.path.dirname(\u001b[34m__file__\u001b[39m)\n\u001b[32m      6\u001b[39m pkg_name = \u001b[34m__name__\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m exportable_classes = \u001b[43minit_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch_classes_from_modules_in_pkg_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpkg_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpkg_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpkg_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpkg_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m exportable_classes.items():\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mglobals\u001b[39m()[k] = v\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/snowflake/ml/_internal/init_utils.py:25\u001b[39m, in \u001b[36mfetch_classes_from_modules_in_pkg_dir\u001b[39m\u001b[34m(pkg_dir, pkg_name)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# import the module and iterate through its attributes\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpkg_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodule_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m attribute_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(module):\n\u001b[32m     27\u001b[39m         attribute = \u001b[38;5;28mgetattr\u001b[39m(module, attribute_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/snowflake/ml/modeling/preprocessing/polynomial_features.py:66\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Modeling library estimators require a smaller sklearn version range.\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m version.Version(SKLEARN_LOWER) <= version.Version(sklearn.__version__) < version.Version(SKLEARN_UPPER):\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m     67\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTo use the modeling library, install scikit-learn version >= \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSKLEARN_LOWER\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and < \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSKLEARN_UPPER\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     68\u001b[39m     )\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPolynomialFeatures\u001b[39;00m(BaseTransformer):\n\u001b[32m     72\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Generate polynomial and interaction features\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[33;03m    For more details on this class, see [sklearn.preprocessing.PolynomialFeatures]\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[33;03m    (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    146\u001b[39m \u001b[33;03m        compute, but may slow down subsequent estimators.\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mException\u001b[39m: To use the modeling library, install scikit-learn version >= 1.4 and < 1.8"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Snowpark\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "# Snowflake ML - Native APIs\n",
    "from snowflake.ml.feature_store import (\n",
    "    FeatureStore, \n",
    "    Entity, \n",
    "    FeatureView,\n",
    "    CreationMode\n",
    ")\n",
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.ml.modeling.preprocessing import OneHotEncoder, StandardScaler\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.ml.modeling.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"✓ Snowflake ML libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "connection",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.222536Z",
     "iopub.status.busy": "2026-01-20T00:17:48.222438Z",
     "iopub.status.idle": "2026-01-20T00:17:48.464660Z",
     "shell.execute_reply": "2026-01-20T00:17:48.464182Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected bytes or RSAPrivateKey, got <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Use CLI connection name\u001b[39;00m\n\u001b[32m      6\u001b[39m connection_name = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mSNOWFLAKE_CONNECTION_NAME\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msfseeeurope_keypair\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m session = \u001b[43mSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconnection_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Set context\u001b[39;00m\n\u001b[32m     11\u001b[39m session.sql(\u001b[33m\"\u001b[39m\u001b[33mUSE DATABASE LIFEARC_POC\u001b[39m\u001b[33m\"\u001b[39m).collect()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/snowflake/snowpark/session.py:505\u001b[39m, in \u001b[36mSession.SessionBuilder.create\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    503\u001b[39m     _add_session(session)\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     session = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconnection\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._app_name:\n\u001b[32m    508\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._format_json:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/snowflake/snowpark/session.py:547\u001b[39m, in \u001b[36mSession.SessionBuilder._create_internal\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mparamstyle\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._options:\n\u001b[32m    545\u001b[39m     \u001b[38;5;28mself\u001b[39m._options[\u001b[33m\"\u001b[39m\u001b[33mparamstyle\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mqmark\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    546\u001b[39m new_session = Session(\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m     ServerConnection({}, conn) \u001b[38;5;28;01mif\u001b[39;00m conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mServerConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_options\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    548\u001b[39m     \u001b[38;5;28mself\u001b[39m._options,\n\u001b[32m    549\u001b[39m )\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mpassword\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._options:\n\u001b[32m    552\u001b[39m     \u001b[38;5;28mself\u001b[39m._options[\u001b[33m\"\u001b[39m\u001b[33mpassword\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/snowflake/snowpark/_internal/server_connection.py:170\u001b[39m, in \u001b[36mServerConnection.__init__\u001b[39m\u001b[34m(self, options, conn)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28mself\u001b[39m._lower_case_parameters = {k.lower(): v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m options.items()}\n\u001b[32m    169\u001b[39m \u001b[38;5;28mself\u001b[39m._add_application_parameters()\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[38;5;28mself\u001b[39m._conn = conn \u001b[38;5;28;01mif\u001b[39;00m conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lower_case_parameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[38;5;28mself\u001b[39m.max_string_size = DEFAULT_STRING_SIZE\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._conn._session_parameters:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/snowflake/connector/__init__.py:54\u001b[39m, in \u001b[36mConnect\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(SnowflakeConnection.\u001b[34m__init__\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mConnect\u001b[39m(**kwargs) -> SnowflakeConnection:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSnowflakeConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/snowflake/connector/connection.py:588\u001b[39m, in \u001b[36mSnowflakeConnection.__init__\u001b[39m\u001b[34m(self, connection_name, connections_file_path, **kwargs)\u001b[39m\n\u001b[32m    586\u001b[39m     kwargs = _get_default_connection_params()\n\u001b[32m    587\u001b[39m \u001b[38;5;28mself\u001b[39m.__set_error_attributes()\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[38;5;28mself\u001b[39m._telemetry = TelemetryClient(\u001b[38;5;28mself\u001b[39m._rest)\n\u001b[32m    590\u001b[39m \u001b[38;5;28mself\u001b[39m.expired = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/snowflake/connector/connection.py:972\u001b[39m, in \u001b[36mSnowflakeConnection.connect\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    970\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(exceptions_dict))\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__open_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/snowflake/connector/connection.py:1371\u001b[39m, in \u001b[36mSnowflakeConnection.__open_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1363\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1364\u001b[39m     \u001b[38;5;66;03m# okta URL, e.g., https://<account>.okta.com/\u001b[39;00m\n\u001b[32m   1365\u001b[39m     \u001b[38;5;28mself\u001b[39m.auth_class = AuthByOkta(\n\u001b[32m   1366\u001b[39m         application=\u001b[38;5;28mself\u001b[39m.application,\n\u001b[32m   1367\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.login_timeout,\n\u001b[32m   1368\u001b[39m         backoff_generator=\u001b[38;5;28mself\u001b[39m._backoff_generator,\n\u001b[32m   1369\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauthenticate_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauth_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28mself\u001b[39m._password = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# ensure password won't persist\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;28mself\u001b[39m.auth_class.reset_secrets()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/snowflake/connector/connection.py:1704\u001b[39m, in \u001b[36mSnowflakeConnection.authenticate_with_retry\u001b[39m\u001b[34m(self, auth_instance)\u001b[39m\n\u001b[32m   1701\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mauthenticate_with_retry\u001b[39m(\u001b[38;5;28mself\u001b[39m, auth_instance) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1702\u001b[39m     \u001b[38;5;66;03m# make some changes if needed before real __authenticate\u001b[39;00m\n\u001b[32m   1703\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1704\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_authenticate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth_instance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1705\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ReauthenticationRequest \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m   1706\u001b[39m         \u001b[38;5;66;03m# cached id_token expiration error, we have cleaned id_token and try to authenticate again\u001b[39;00m\n\u001b[32m   1707\u001b[39m         logger.debug(\u001b[33m\"\u001b[39m\u001b[33mID token expired. Reauthenticating...: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, ex)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/snowflake/connector/connection.py:1720\u001b[39m, in \u001b[36mSnowflakeConnection._authenticate\u001b[39m\u001b[34m(self, auth_instance)\u001b[39m\n\u001b[32m   1719\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_authenticate\u001b[39m(\u001b[38;5;28mself\u001b[39m, auth_instance: AuthByPlugin):\n\u001b[32m-> \u001b[39m\u001b[32m1720\u001b[39m     \u001b[43mauth_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1721\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1722\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauthenticator\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_authenticator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1723\u001b[39m \u001b[43m        \u001b[49m\u001b[43mservice_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mservice_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1724\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccount\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccount\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1725\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1726\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1727\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1728\u001b[39m     \u001b[38;5;28mself\u001b[39m._consent_cache_id_token = \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   1729\u001b[39m         auth_instance, \u001b[33m\"\u001b[39m\u001b[33mconsent_cache_id_token\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1730\u001b[39m     )\n\u001b[32m   1732\u001b[39m     auth = Auth(\u001b[38;5;28mself\u001b[39m.rest)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.12/site-packages/snowflake/connector/auth/keypair.py:139\u001b[39m, in \u001b[36mAuthByKeyPair.prepare\u001b[39m\u001b[34m(self, account, user, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     private_key = \u001b[38;5;28mself\u001b[39m._private_key\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    140\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected bytes or RSAPrivateKey, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m._private_key)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    141\u001b[39m     )\n\u001b[32m    143\u001b[39m public_key_fp = \u001b[38;5;28mself\u001b[39m.calculate_public_key_fingerprint(private_key)\n\u001b[32m    145\u001b[39m \u001b[38;5;28mself\u001b[39m._jwt_token_exp = now + \u001b[38;5;28mself\u001b[39m._lifetime\n",
      "\u001b[31mTypeError\u001b[39m: Expected bytes or RSAPrivateKey, got <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# Connection using connection_name (CLI-style connection)\n",
    "import os\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Use CLI connection name\n",
    "connection_name = os.environ.get(\"SNOWFLAKE_CONNECTION_NAME\", \"sfseeeurope_keypair\")\n",
    "\n",
    "session = Session.builder.config(\"connection_name\", connection_name).create()\n",
    "\n",
    "# Set context\n",
    "session.sql(\"USE DATABASE LIFEARC_POC\").collect()\n",
    "session.sql(\"USE SCHEMA ML_DEMO\").collect()\n",
    "session.sql(\"USE WAREHOUSE COMPUTE_WH\").collect()\n",
    "\n",
    "# Verify connection\n",
    "print(f\"✓ Connected via {connection_name}\")\n",
    "print(f\"Database: {session.get_current_database()}\")\n",
    "print(f\"Schema: {session.get_current_schema()}\")\n",
    "print(f\"Warehouse: {session.get_current_warehouse()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discovery-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Data Discovery & EDA\n",
    "\n",
    "Explore the clinical trial data to understand feature candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load-data",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.466961Z",
     "iopub.status.busy": "2026-01-20T00:17:48.466838Z",
     "iopub.status.idle": "2026-01-20T00:17:48.482030Z",
     "shell.execute_reply": "2026-01-20T00:17:48.481718Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load clinical trial results\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m clinical_df = \u001b[43msession\u001b[49m.table(\u001b[33m\"\u001b[39m\u001b[33mLIFEARC_POC.DATA_SHARING.CLINICAL_TRIAL_RESULTS\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal records: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclinical_df.count()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSchema:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'session' is not defined"
     ]
    }
   ],
   "source": [
    "# Load clinical trial results\n",
    "clinical_df = session.table(\"LIFEARC_POC.DATA_SHARING.CLINICAL_TRIAL_RESULTS\")\n",
    "\n",
    "print(f\"Total records: {clinical_df.count():,}\")\n",
    "print(f\"\\nSchema:\")\n",
    "for field in clinical_df.schema.fields:\n",
    "    print(f\"  {field.name}: {field.datatype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda-summary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.483583Z",
     "iopub.status.busy": "2026-01-20T00:17:48.483483Z",
     "iopub.status.idle": "2026-01-20T00:17:48.497354Z",
     "shell.execute_reply": "2026-01-20T00:17:48.497056Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clinical_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Response category distribution (target variable)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m response_dist = \u001b[43mclinical_df\u001b[49m.group_by(\u001b[33m\"\u001b[39m\u001b[33mRESPONSE_CATEGORY\u001b[39m\u001b[33m\"\u001b[39m).count().order_by(\u001b[33m\"\u001b[39m\u001b[33mCOUNT\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      3\u001b[39m response_dist.show()\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# This is what we're predicting - patient response to treatment\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'clinical_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Response category distribution (target variable)\n",
    "response_dist = clinical_df.group_by(\"RESPONSE_CATEGORY\").count().order_by(\"COUNT\", ascending=False)\n",
    "response_dist.show()\n",
    "\n",
    "# This is what we're predicting - patient response to treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eda-features",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.498844Z",
     "iopub.status.busy": "2026-01-20T00:17:48.498756Z",
     "iopub.status.idle": "2026-01-20T00:17:48.516661Z",
     "shell.execute_reply": "2026-01-20T00:17:48.516314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Biomarker Status ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clinical_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Explore feature distributions\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Biomarker Status ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mclinical_df\u001b[49m.group_by(\u001b[33m\"\u001b[39m\u001b[33mBIOMARKER_STATUS\u001b[39m\u001b[33m\"\u001b[39m).agg(\n\u001b[32m      4\u001b[39m     F.count(\u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m).alias(\u001b[33m\"\u001b[39m\u001b[33mCOUNT\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      5\u001b[39m     F.avg(\u001b[33m\"\u001b[39m\u001b[33mPFS_MONTHS\u001b[39m\u001b[33m\"\u001b[39m).alias(\u001b[33m\"\u001b[39m\u001b[33mAVG_PFS\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m ).show()\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== ctDNA Confirmation ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m clinical_df.group_by(\u001b[33m\"\u001b[39m\u001b[33mCTDNA_CONFIRMATION\u001b[39m\u001b[33m\"\u001b[39m).agg(\n\u001b[32m     10\u001b[39m     F.count(\u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m).alias(\u001b[33m\"\u001b[39m\u001b[33mCOUNT\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     11\u001b[39m     F.avg(\u001b[33m\"\u001b[39m\u001b[33mPFS_MONTHS\u001b[39m\u001b[33m\"\u001b[39m).alias(\u001b[33m\"\u001b[39m\u001b[33mAVG_PFS\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m ).show()\n",
      "\u001b[31mNameError\u001b[39m: name 'clinical_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Explore feature distributions\n",
    "print(\"=== Biomarker Status ===\")\n",
    "clinical_df.group_by(\"BIOMARKER_STATUS\").agg(\n",
    "    F.count(\"*\").alias(\"COUNT\"),\n",
    "    F.avg(\"PFS_MONTHS\").alias(\"AVG_PFS\")\n",
    ").show()\n",
    "\n",
    "print(\"\\n=== ctDNA Confirmation ===\")\n",
    "clinical_df.group_by(\"CTDNA_CONFIRMATION\").agg(\n",
    "    F.count(\"*\").alias(\"COUNT\"),\n",
    "    F.avg(\"PFS_MONTHS\").alias(\"AVG_PFS\")\n",
    ").show()\n",
    "\n",
    "print(\"\\n=== Treatment Arm Performance ===\")\n",
    "clinical_df.group_by(\"TREATMENT_ARM\").agg(\n",
    "    F.count(\"*\").alias(\"COUNT\"),\n",
    "    F.avg(\"PFS_MONTHS\").alias(\"AVG_PFS\"),\n",
    "    F.avg(\"OS_MONTHS\").alias(\"AVG_OS\")\n",
    ").order_by(\"AVG_PFS\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eda-correlations",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.518321Z",
     "iopub.status.busy": "2026-01-20T00:17:48.518231Z",
     "iopub.status.idle": "2026-01-20T00:17:48.534593Z",
     "shell.execute_reply": "2026-01-20T00:17:48.534264Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clinical_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Response rate by biomarker + ctDNA combination\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# This is the kind of insight that drives trial design\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response_analysis = \u001b[43mclinical_df\u001b[49m.with_column(\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mIS_RESPONDER\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     F.when(F.col(\u001b[33m\"\u001b[39m\u001b[33mRESPONSE_CATEGORY\u001b[39m\u001b[33m\"\u001b[39m).isin([\u001b[33m\"\u001b[39m\u001b[33mComplete_Response\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPartial_Response\u001b[39m\u001b[33m\"\u001b[39m]), \u001b[32m1\u001b[39m).otherwise(\u001b[32m0\u001b[39m)\n\u001b[32m      7\u001b[39m ).group_by(\u001b[33m\"\u001b[39m\u001b[33mBIOMARKER_STATUS\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mCTDNA_CONFIRMATION\u001b[39m\u001b[33m\"\u001b[39m).agg(\n\u001b[32m      8\u001b[39m     F.count(\u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m).alias(\u001b[33m\"\u001b[39m\u001b[33mPATIENTS\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      9\u001b[39m     F.sum(\u001b[33m\"\u001b[39m\u001b[33mIS_RESPONDER\u001b[39m\u001b[33m\"\u001b[39m).alias(\u001b[33m\"\u001b[39m\u001b[33mRESPONDERS\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     10\u001b[39m     (F.sum(\u001b[33m\"\u001b[39m\u001b[33mIS_RESPONDER\u001b[39m\u001b[33m\"\u001b[39m) / F.count(\u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m) * \u001b[32m100\u001b[39m).alias(\u001b[33m\"\u001b[39m\u001b[33mRESPONSE_RATE_PCT\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m ).order_by(\u001b[33m\"\u001b[39m\u001b[33mRESPONSE_RATE_PCT\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mResponse Rate by Biomarker + ctDNA Confirmation:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m response_analysis.show()\n",
      "\u001b[31mNameError\u001b[39m: name 'clinical_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Response rate by biomarker + ctDNA combination\n",
    "# This is the kind of insight that drives trial design\n",
    "\n",
    "response_analysis = clinical_df.with_column(\n",
    "    \"IS_RESPONDER\",\n",
    "    F.when(F.col(\"RESPONSE_CATEGORY\").isin([\"Complete_Response\", \"Partial_Response\"]), 1).otherwise(0)\n",
    ").group_by(\"BIOMARKER_STATUS\", \"CTDNA_CONFIRMATION\").agg(\n",
    "    F.count(\"*\").alias(\"PATIENTS\"),\n",
    "    F.sum(\"IS_RESPONDER\").alias(\"RESPONDERS\"),\n",
    "    (F.sum(\"IS_RESPONDER\") / F.count(\"*\") * 100).alias(\"RESPONSE_RATE_PCT\")\n",
    ").order_by(\"RESPONSE_RATE_PCT\", ascending=False)\n",
    "\n",
    "print(\"Response Rate by Biomarker + ctDNA Confirmation:\")\n",
    "response_analysis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-store-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Snowflake Feature Store\n",
    "\n",
    "Create a **native Snowflake Feature Store** with:\n",
    "- Entities (Patient, Trial)\n",
    "- Feature Views with automatic refresh\n",
    "- Point-in-time correct feature retrieval\n",
    "\n",
    "**Why Feature Store matters for Life Sciences:**\n",
    "- Reproducibility for regulatory submissions\n",
    "- Consistent features across training and inference\n",
    "- Automatic lineage tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feature-store-init",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.536049Z",
     "iopub.status.busy": "2026-01-20T00:17:48.535954Z",
     "iopub.status.idle": "2026-01-20T00:17:48.550517Z",
     "shell.execute_reply": "2026-01-20T00:17:48.550198Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize Feature Store\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# The Feature Store is just a schema - we'll create a dedicated one\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43msession\u001b[49m.sql(\u001b[33m\"\u001b[39m\u001b[33mCREATE SCHEMA IF NOT EXISTS LIFEARC_POC.ML_FEATURE_STORE\u001b[39m\u001b[33m\"\u001b[39m).collect()\n\u001b[32m      6\u001b[39m fs = FeatureStore(\n\u001b[32m      7\u001b[39m     session=session,\n\u001b[32m      8\u001b[39m     database=\u001b[33m\"\u001b[39m\u001b[33mLIFEARC_POC\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ Feature Store initialized: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfs.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'session' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize Feature Store\n",
    "# The Feature Store is just a schema - we'll create a dedicated one\n",
    "\n",
    "session.sql(\"CREATE SCHEMA IF NOT EXISTS LIFEARC_POC.ML_FEATURE_STORE\").collect()\n",
    "\n",
    "fs = FeatureStore(\n",
    "    session=session,\n",
    "    database=\"LIFEARC_POC\",\n",
    "    name=\"ML_FEATURE_STORE\",\n",
    "    default_warehouse=\"COMPUTE_WH\",\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n",
    ")\n",
    "\n",
    "print(f\"✓ Feature Store initialized: {fs.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "create-entities",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.552243Z",
     "iopub.status.busy": "2026-01-20T00:17:48.552128Z",
     "iopub.status.idle": "2026-01-20T00:17:48.569461Z",
     "shell.execute_reply": "2026-01-20T00:17:48.569062Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     11\u001b[39m trial_entity = Entity(\n\u001b[32m     12\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mTRIAL\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     join_keys=[\u001b[33m\"\u001b[39m\u001b[33mTRIAL_ID\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     14\u001b[39m     desc=\u001b[33m\"\u001b[39m\u001b[33mClinical trial identifier\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Register entities\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mfs\u001b[49m.register_entity(patient_entity)\n\u001b[32m     19\u001b[39m fs.register_entity(trial_entity)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ Entities registered:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'fs' is not defined"
     ]
    }
   ],
   "source": [
    "# Define entities - the subjects of our features\n",
    "\n",
    "# Patient entity - each row represents a unique patient in a trial\n",
    "patient_entity = Entity(\n",
    "    name=\"PATIENT\",\n",
    "    join_keys=[\"PATIENT_ID\"],\n",
    "    desc=\"Individual patient enrolled in clinical trial\"\n",
    ")\n",
    "\n",
    "# Trial entity - for trial-level features\n",
    "trial_entity = Entity(\n",
    "    name=\"TRIAL\",\n",
    "    join_keys=[\"TRIAL_ID\"],\n",
    "    desc=\"Clinical trial identifier\"\n",
    ")\n",
    "\n",
    "# Register entities\n",
    "fs.register_entity(patient_entity)\n",
    "fs.register_entity(trial_entity)\n",
    "\n",
    "print(\"✓ Entities registered:\")\n",
    "for entity in fs.list_entities().to_pandas().itertuples():\n",
    "    print(f\"  - {entity.NAME}: {entity.JOIN_KEYS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "patient-features",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.571234Z",
     "iopub.status.busy": "2026-01-20T00:17:48.571100Z",
     "iopub.status.idle": "2026-01-20T00:17:48.587549Z",
     "shell.execute_reply": "2026-01-20T00:17:48.587214Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create Patient Feature View\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# These are features derived from patient-level clinical data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m patient_features_df = \u001b[43msession\u001b[49m.sql(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33m    SELECT \u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33m        PATIENT_ID,\u001b[39m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[33m        -- Demographics (encoded)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m        PATIENT_AGE,\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33m        CASE WHEN PATIENT_AGE < 50 THEN \u001b[39m\u001b[33m'\u001b[39m\u001b[33mYOUNG\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m             WHEN PATIENT_AGE < 65 THEN \u001b[39m\u001b[33m'\u001b[39m\u001b[33mMIDDLE\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[33m             ELSE \u001b[39m\u001b[33m'\u001b[39m\u001b[33mSENIOR\u001b[39m\u001b[33m'\u001b[39m\u001b[33m END AS AGE_GROUP,\u001b[39m\n\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m \u001b[33m        -- Biomarker features\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m        BIOMARKER_STATUS,\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m        CASE WHEN BIOMARKER_STATUS = \u001b[39m\u001b[33m'\u001b[39m\u001b[33mPOSITIVE\u001b[39m\u001b[33m'\u001b[39m\u001b[33m THEN 1 ELSE 0 END AS BIOMARKER_POSITIVE,\u001b[39m\n\u001b[32m     17\u001b[39m \n\u001b[32m     18\u001b[39m \u001b[33m        -- ctDNA features  \u001b[39m\n\u001b[32m     19\u001b[39m \u001b[33m        CTDNA_CONFIRMATION,\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[33m        CASE WHEN CTDNA_CONFIRMATION = \u001b[39m\u001b[33m'\u001b[39m\u001b[33mYES\u001b[39m\u001b[33m'\u001b[39m\u001b[33m THEN 1 ELSE 0 END AS CTDNA_CONFIRMED,\u001b[39m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[33m        -- Treatment features\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[33m        TREATMENT_ARM,\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33m        CASE TREATMENT_ARM \u001b[39m\n\u001b[32m     25\u001b[39m \u001b[33m            WHEN \u001b[39m\u001b[33m'\u001b[39m\u001b[33mCombination\u001b[39m\u001b[33m'\u001b[39m\u001b[33m THEN 3\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[33m            WHEN \u001b[39m\u001b[33m'\u001b[39m\u001b[33mExperimental\u001b[39m\u001b[33m'\u001b[39m\u001b[33m THEN 2\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[33m            WHEN \u001b[39m\u001b[33m'\u001b[39m\u001b[33mStandard\u001b[39m\u001b[33m'\u001b[39m\u001b[33m THEN 1\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[33m            ELSE 0 END AS TREATMENT_INTENSITY,\u001b[39m\n\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m \u001b[33m        -- Cohort features\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[33m        COHORT,\u001b[39m\n\u001b[32m     32\u001b[39m \n\u001b[32m     33\u001b[39m \u001b[33m        -- Timestamp for point-in-time correctness\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[33m        CURRENT_TIMESTAMP() AS FEATURE_TIMESTAMP\u001b[39m\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m \u001b[33m    FROM LIFEARC_POC.DATA_SHARING.CLINICAL_TRIAL_RESULTS\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Create feature view with managed refresh\u001b[39;00m\n\u001b[32m     40\u001b[39m patient_fv = FeatureView(\n\u001b[32m     41\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mPATIENT_CLINICAL_FEATURES\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     42\u001b[39m     entities=[patient_entity],\n\u001b[32m   (...)\u001b[39m\u001b[32m     46\u001b[39m     desc=\u001b[33m\"\u001b[39m\u001b[33mPatient-level clinical features for response prediction\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     47\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'session' is not defined"
     ]
    }
   ],
   "source": [
    "# Create Patient Feature View\n",
    "# These are features derived from patient-level clinical data\n",
    "\n",
    "patient_features_df = session.sql(\"\"\"\n",
    "    SELECT \n",
    "        PATIENT_ID,\n",
    "        \n",
    "        -- Demographics (encoded)\n",
    "        PATIENT_AGE,\n",
    "        CASE WHEN PATIENT_AGE < 50 THEN 'YOUNG'\n",
    "             WHEN PATIENT_AGE < 65 THEN 'MIDDLE'\n",
    "             ELSE 'SENIOR' END AS AGE_GROUP,\n",
    "        \n",
    "        -- Biomarker features\n",
    "        BIOMARKER_STATUS,\n",
    "        CASE WHEN BIOMARKER_STATUS = 'POSITIVE' THEN 1 ELSE 0 END AS BIOMARKER_POSITIVE,\n",
    "        \n",
    "        -- ctDNA features  \n",
    "        CTDNA_CONFIRMATION,\n",
    "        CASE WHEN CTDNA_CONFIRMATION = 'YES' THEN 1 ELSE 0 END AS CTDNA_CONFIRMED,\n",
    "        \n",
    "        -- Treatment features\n",
    "        TREATMENT_ARM,\n",
    "        CASE TREATMENT_ARM \n",
    "            WHEN 'Combination' THEN 3\n",
    "            WHEN 'Experimental' THEN 2\n",
    "            WHEN 'Standard' THEN 1\n",
    "            ELSE 0 END AS TREATMENT_INTENSITY,\n",
    "        \n",
    "        -- Cohort features\n",
    "        COHORT,\n",
    "        \n",
    "        -- Timestamp for point-in-time correctness\n",
    "        CURRENT_TIMESTAMP() AS FEATURE_TIMESTAMP\n",
    "        \n",
    "    FROM LIFEARC_POC.DATA_SHARING.CLINICAL_TRIAL_RESULTS\n",
    "\"\"\")\n",
    "\n",
    "# Create feature view with managed refresh\n",
    "patient_fv = FeatureView(\n",
    "    name=\"PATIENT_CLINICAL_FEATURES\",\n",
    "    entities=[patient_entity],\n",
    "    feature_df=patient_features_df,\n",
    "    timestamp_col=\"FEATURE_TIMESTAMP\",\n",
    "    refresh_freq=\"1 day\",  # Auto-refresh daily\n",
    "    desc=\"Patient-level clinical features for response prediction\"\n",
    ")\n",
    "\n",
    "# Register the feature view\n",
    "patient_fv = fs.register_feature_view(\n",
    "    feature_view=patient_fv,\n",
    "    version=\"V1\",\n",
    "    block=True  # Wait for initial materialization\n",
    ")\n",
    "\n",
    "print(f\"✓ Feature View registered: {patient_fv.name}\")\n",
    "print(f\"  Features: {[f.name for f in patient_fv.feature_descs]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "trial-features",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.589025Z",
     "iopub.status.busy": "2026-01-20T00:17:48.588945Z",
     "iopub.status.idle": "2026-01-20T00:17:48.603414Z",
     "shell.execute_reply": "2026-01-20T00:17:48.603020Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create Trial-level Feature View\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Aggregate statistics per trial that can inform patient outcomes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m trial_features_df = \u001b[43msession\u001b[49m.sql(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33m    SELECT \u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33m        TRIAL_ID,\u001b[39m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[33m        -- Trial performance metrics\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m        COUNT(*) AS TRIAL_ENROLLMENT,\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33m        AVG(PFS_MONTHS) AS TRIAL_AVG_PFS,\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m        STDDEV(PFS_MONTHS) AS TRIAL_STD_PFS,\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[33m        AVG(OS_MONTHS) AS TRIAL_AVG_OS,\u001b[39m\n\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m \u001b[33m        -- Response rates by trial\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m        SUM(CASE WHEN RESPONSE_CATEGORY IN (\u001b[39m\u001b[33m'\u001b[39m\u001b[33mComplete_Response\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mPartial_Response\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) \u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m            THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS TRIAL_RESPONSE_RATE,\u001b[39m\n\u001b[32m     17\u001b[39m \n\u001b[32m     18\u001b[39m \u001b[33m        -- Biomarker prevalence in trial\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[33m        SUM(CASE WHEN BIOMARKER_STATUS = \u001b[39m\u001b[33m'\u001b[39m\u001b[33mPOSITIVE\u001b[39m\u001b[33m'\u001b[39m\u001b[33m THEN 1 ELSE 0 END) * 100.0 / COUNT(*) \u001b[39m\n\u001b[32m     20\u001b[39m \u001b[33m            AS TRIAL_BIOMARKER_POSITIVE_PCT,\u001b[39m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[33m        -- ctDNA usage in trial\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[33m        SUM(CASE WHEN CTDNA_CONFIRMATION = \u001b[39m\u001b[33m'\u001b[39m\u001b[33mYES\u001b[39m\u001b[33m'\u001b[39m\u001b[33m THEN 1 ELSE 0 END) * 100.0 / COUNT(*) \u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33m            AS TRIAL_CTDNA_USAGE_PCT,\u001b[39m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[33m        CURRENT_TIMESTAMP() AS FEATURE_TIMESTAMP\u001b[39m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[33m    FROM LIFEARC_POC.DATA_SHARING.CLINICAL_TRIAL_RESULTS\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[33m    GROUP BY TRIAL_ID\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     32\u001b[39m trial_fv = FeatureView(\n\u001b[32m     33\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mTRIAL_AGGREGATE_FEATURES\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     34\u001b[39m     entities=[trial_entity],\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m     desc=\u001b[33m\"\u001b[39m\u001b[33mTrial-level aggregate features\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     39\u001b[39m )\n\u001b[32m     41\u001b[39m trial_fv = fs.register_feature_view(\n\u001b[32m     42\u001b[39m     feature_view=trial_fv,\n\u001b[32m     43\u001b[39m     version=\u001b[33m\"\u001b[39m\u001b[33mV1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     44\u001b[39m     block=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     45\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'session' is not defined"
     ]
    }
   ],
   "source": [
    "# Create Trial-level Feature View\n",
    "# Aggregate statistics per trial that can inform patient outcomes\n",
    "\n",
    "trial_features_df = session.sql(\"\"\"\n",
    "    SELECT \n",
    "        TRIAL_ID,\n",
    "        \n",
    "        -- Trial performance metrics\n",
    "        COUNT(*) AS TRIAL_ENROLLMENT,\n",
    "        AVG(PFS_MONTHS) AS TRIAL_AVG_PFS,\n",
    "        STDDEV(PFS_MONTHS) AS TRIAL_STD_PFS,\n",
    "        AVG(OS_MONTHS) AS TRIAL_AVG_OS,\n",
    "        \n",
    "        -- Response rates by trial\n",
    "        SUM(CASE WHEN RESPONSE_CATEGORY IN ('Complete_Response', 'Partial_Response') \n",
    "            THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS TRIAL_RESPONSE_RATE,\n",
    "        \n",
    "        -- Biomarker prevalence in trial\n",
    "        SUM(CASE WHEN BIOMARKER_STATUS = 'POSITIVE' THEN 1 ELSE 0 END) * 100.0 / COUNT(*) \n",
    "            AS TRIAL_BIOMARKER_POSITIVE_PCT,\n",
    "        \n",
    "        -- ctDNA usage in trial\n",
    "        SUM(CASE WHEN CTDNA_CONFIRMATION = 'YES' THEN 1 ELSE 0 END) * 100.0 / COUNT(*) \n",
    "            AS TRIAL_CTDNA_USAGE_PCT,\n",
    "        \n",
    "        CURRENT_TIMESTAMP() AS FEATURE_TIMESTAMP\n",
    "        \n",
    "    FROM LIFEARC_POC.DATA_SHARING.CLINICAL_TRIAL_RESULTS\n",
    "    GROUP BY TRIAL_ID\n",
    "\"\"\")\n",
    "\n",
    "trial_fv = FeatureView(\n",
    "    name=\"TRIAL_AGGREGATE_FEATURES\",\n",
    "    entities=[trial_entity],\n",
    "    feature_df=trial_features_df,\n",
    "    timestamp_col=\"FEATURE_TIMESTAMP\",\n",
    "    refresh_freq=\"1 day\",\n",
    "    desc=\"Trial-level aggregate features\"\n",
    ")\n",
    "\n",
    "trial_fv = fs.register_feature_view(\n",
    "    feature_view=trial_fv,\n",
    "    version=\"V1\",\n",
    "    block=True\n",
    ")\n",
    "\n",
    "print(f\"✓ Feature View registered: {trial_fv.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "list-features",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.604958Z",
     "iopub.status.busy": "2026-01-20T00:17:48.604874Z",
     "iopub.status.idle": "2026-01-20T00:17:48.617837Z",
     "shell.execute_reply": "2026-01-20T00:17:48.617404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Feature Store Contents ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# List all feature views in our store\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Feature Store Contents ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mfs\u001b[49m.list_feature_views().to_pandas()\n",
      "\u001b[31mNameError\u001b[39m: name 'fs' is not defined"
     ]
    }
   ],
   "source": [
    "# List all feature views in our store\n",
    "print(\"=== Feature Store Contents ===\")\n",
    "fs.list_feature_views().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Generate Training Dataset\n",
    "\n",
    "Use the Feature Store to generate a **point-in-time correct** training dataset.\n",
    "\n",
    "This ensures:\n",
    "- No data leakage (features computed before label observation)\n",
    "- Reproducibility (same dataset can be regenerated)\n",
    "- Lineage tracking (automatic connection to models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spine-table",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.619727Z",
     "iopub.status.busy": "2026-01-20T00:17:48.619569Z",
     "iopub.status.idle": "2026-01-20T00:17:48.634686Z",
     "shell.execute_reply": "2026-01-20T00:17:48.634350Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create spine table - the join keys and labels for training\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# This is the \"ground truth\" we're trying to predict\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m spine_df = \u001b[43msession\u001b[49m.sql(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33m    SELECT \u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33m        RESULT_ID,\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33m        PATIENT_ID,\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m        TRIAL_ID,\u001b[39m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[33m        -- Target variable (what we\u001b[39m\u001b[33m'\u001b[39m\u001b[33mre predicting)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m        RESPONSE_CATEGORY,\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[33m        CASE RESPONSE_CATEGORY\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[33m            WHEN \u001b[39m\u001b[33m'\u001b[39m\u001b[33mComplete_Response\u001b[39m\u001b[33m'\u001b[39m\u001b[33m THEN 3\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33m            WHEN \u001b[39m\u001b[33m'\u001b[39m\u001b[33mPartial_Response\u001b[39m\u001b[33m'\u001b[39m\u001b[33m THEN 2\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m            WHEN \u001b[39m\u001b[33m'\u001b[39m\u001b[33mStable_Disease\u001b[39m\u001b[33m'\u001b[39m\u001b[33m THEN 1\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m            WHEN \u001b[39m\u001b[33m'\u001b[39m\u001b[33mProgressive_Disease\u001b[39m\u001b[33m'\u001b[39m\u001b[33m THEN 0\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[33m            ELSE -1 END AS RESPONSE_LABEL,\u001b[39m\n\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m \u001b[33m        -- Binary target (responder vs non-responder)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[33m        CASE WHEN RESPONSE_CATEGORY IN (\u001b[39m\u001b[33m'\u001b[39m\u001b[33mComplete_Response\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mPartial_Response\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) \u001b[39m\n\u001b[32m     21\u001b[39m \u001b[33m            THEN 1 ELSE 0 END AS IS_RESPONDER,\u001b[39m\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[33m        -- Timestamp for point-in-time join\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33m        CURRENT_TIMESTAMP() AS LABEL_TIMESTAMP\u001b[39m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[33m    FROM LIFEARC_POC.DATA_SHARING.CLINICAL_TRIAL_RESULTS\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[33m    WHERE RESPONSE_CATEGORY IS NOT NULL\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSpine table rows: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspine_df.count()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m spine_df.show(\u001b[32m5\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'session' is not defined"
     ]
    }
   ],
   "source": [
    "# Create spine table - the join keys and labels for training\n",
    "# This is the \"ground truth\" we're trying to predict\n",
    "\n",
    "spine_df = session.sql(\"\"\"\n",
    "    SELECT \n",
    "        RESULT_ID,\n",
    "        PATIENT_ID,\n",
    "        TRIAL_ID,\n",
    "        \n",
    "        -- Target variable (what we're predicting)\n",
    "        RESPONSE_CATEGORY,\n",
    "        CASE RESPONSE_CATEGORY\n",
    "            WHEN 'Complete_Response' THEN 3\n",
    "            WHEN 'Partial_Response' THEN 2\n",
    "            WHEN 'Stable_Disease' THEN 1\n",
    "            WHEN 'Progressive_Disease' THEN 0\n",
    "            ELSE -1 END AS RESPONSE_LABEL,\n",
    "        \n",
    "        -- Binary target (responder vs non-responder)\n",
    "        CASE WHEN RESPONSE_CATEGORY IN ('Complete_Response', 'Partial_Response') \n",
    "            THEN 1 ELSE 0 END AS IS_RESPONDER,\n",
    "        \n",
    "        -- Timestamp for point-in-time join\n",
    "        CURRENT_TIMESTAMP() AS LABEL_TIMESTAMP\n",
    "        \n",
    "    FROM LIFEARC_POC.DATA_SHARING.CLINICAL_TRIAL_RESULTS\n",
    "    WHERE RESPONSE_CATEGORY IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Spine table rows: {spine_df.count():,}\")\n",
    "spine_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "generate-dataset",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.636257Z",
     "iopub.status.busy": "2026-01-20T00:17:48.636168Z",
     "iopub.status.idle": "2026-01-20T00:17:48.651710Z",
     "shell.execute_reply": "2026-01-20T00:17:48.651350Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Generate training dataset by joining features to spine\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# The Feature Store handles point-in-time correctness automatically\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m training_dataset = \u001b[43mfs\u001b[49m.generate_dataset(\n\u001b[32m      5\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mRESPONSE_PREDICTION_TRAINING\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     version=\u001b[33m\"\u001b[39m\u001b[33mV1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     spine_df=spine_df,\n\u001b[32m      8\u001b[39m     features=[\n\u001b[32m      9\u001b[39m         patient_fv,  \u001b[38;5;66;03m# All patient features\u001b[39;00m\n\u001b[32m     10\u001b[39m         trial_fv     \u001b[38;5;66;03m# All trial features\u001b[39;00m\n\u001b[32m     11\u001b[39m     ],\n\u001b[32m     12\u001b[39m     spine_timestamp_col=\u001b[33m\"\u001b[39m\u001b[33mLABEL_TIMESTAMP\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     spine_label_cols=[\u001b[33m\"\u001b[39m\u001b[33mRESPONSE_CATEGORY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mRESPONSE_LABEL\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mIS_RESPONDER\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     14\u001b[39m     desc=\u001b[33m\"\u001b[39m\u001b[33mTraining dataset for clinical response prediction\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Convert to DataFrame for training\u001b[39;00m\n\u001b[32m     18\u001b[39m training_df = training_dataset.read.to_snowpark_dataframe()\n",
      "\u001b[31mNameError\u001b[39m: name 'fs' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate training dataset by joining features to spine\n",
    "# The Feature Store handles point-in-time correctness automatically\n",
    "\n",
    "training_dataset = fs.generate_dataset(\n",
    "    name=\"RESPONSE_PREDICTION_TRAINING\",\n",
    "    version=\"V1\",\n",
    "    spine_df=spine_df,\n",
    "    features=[\n",
    "        patient_fv,  # All patient features\n",
    "        trial_fv     # All trial features\n",
    "    ],\n",
    "    spine_timestamp_col=\"LABEL_TIMESTAMP\",\n",
    "    spine_label_cols=[\"RESPONSE_CATEGORY\", \"RESPONSE_LABEL\", \"IS_RESPONDER\"],\n",
    "    desc=\"Training dataset for clinical response prediction\"\n",
    ")\n",
    "\n",
    "# Convert to DataFrame for training\n",
    "training_df = training_dataset.read.to_snowpark_dataframe()\n",
    "print(f\"\\n✓ Training dataset generated: {training_df.count():,} rows\")\n",
    "print(f\"  Columns: {training_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "train-test-split",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.653240Z",
     "iopub.status.busy": "2026-01-20T00:17:48.653144Z",
     "iopub.status.idle": "2026-01-20T00:17:48.669056Z",
     "shell.execute_reply": "2026-01-20T00:17:48.668742Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Split into train/validation/test sets\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Using hash-based split for reproducibility\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m train_df = \u001b[43mtraining_df\u001b[49m.filter(F.abs(F.hash(\u001b[33m\"\u001b[39m\u001b[33mRESULT_ID\u001b[39m\u001b[33m\"\u001b[39m)) % \u001b[32m10\u001b[39m < \u001b[32m7\u001b[39m)  \u001b[38;5;66;03m# 70%\u001b[39;00m\n\u001b[32m      5\u001b[39m val_df = training_df.filter((F.abs(F.hash(\u001b[33m\"\u001b[39m\u001b[33mRESULT_ID\u001b[39m\u001b[33m\"\u001b[39m)) % \u001b[32m10\u001b[39m >= \u001b[32m7\u001b[39m) & \n\u001b[32m      6\u001b[39m                             (F.abs(F.hash(\u001b[33m\"\u001b[39m\u001b[33mRESULT_ID\u001b[39m\u001b[33m\"\u001b[39m)) % \u001b[32m10\u001b[39m < \u001b[32m9\u001b[39m))  \u001b[38;5;66;03m# 20%\u001b[39;00m\n\u001b[32m      7\u001b[39m test_df = training_df.filter(F.abs(F.hash(\u001b[33m\"\u001b[39m\u001b[33mRESULT_ID\u001b[39m\u001b[33m\"\u001b[39m)) % \u001b[32m10\u001b[39m >= \u001b[32m9\u001b[39m)  \u001b[38;5;66;03m# 10%\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'training_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Split into train/validation/test sets\n",
    "# Using hash-based split for reproducibility\n",
    "\n",
    "train_df = training_df.filter(F.abs(F.hash(\"RESULT_ID\")) % 10 < 7)  # 70%\n",
    "val_df = training_df.filter((F.abs(F.hash(\"RESULT_ID\")) % 10 >= 7) & \n",
    "                            (F.abs(F.hash(\"RESULT_ID\")) % 10 < 9))  # 20%\n",
    "test_df = training_df.filter(F.abs(F.hash(\"RESULT_ID\")) % 10 >= 9)  # 10%\n",
    "\n",
    "print(f\"Training set: {train_df.count():,} rows\")\n",
    "print(f\"Validation set: {val_df.count():,} rows\")\n",
    "print(f\"Test set: {test_df.count():,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-training-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Model Training with Snowpark ML\n",
    "\n",
    "Train a classification model using **Snowpark ML** - no data leaves Snowflake.\n",
    "\n",
    "Benefits:\n",
    "- Data stays under governance\n",
    "- Distributed training on Snowflake compute\n",
    "- Native integration with Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "define-features",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.670581Z",
     "iopub.status.busy": "2026-01-20T00:17:48.670490Z",
     "iopub.status.idle": "2026-01-20T00:17:48.672948Z",
     "shell.execute_reply": "2026-01-20T00:17:48.672650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: 9\n",
      "Categorical features: 4\n",
      "Target: IS_RESPONDER\n"
     ]
    }
   ],
   "source": [
    "# Define feature columns for training\n",
    "NUMERIC_FEATURES = [\n",
    "    \"PATIENT_AGE\",\n",
    "    \"BIOMARKER_POSITIVE\",\n",
    "    \"CTDNA_CONFIRMED\",\n",
    "    \"TREATMENT_INTENSITY\",\n",
    "    \"TRIAL_ENROLLMENT\",\n",
    "    \"TRIAL_AVG_PFS\",\n",
    "    \"TRIAL_RESPONSE_RATE\",\n",
    "    \"TRIAL_BIOMARKER_POSITIVE_PCT\",\n",
    "    \"TRIAL_CTDNA_USAGE_PCT\"\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES = [\n",
    "    \"AGE_GROUP\",\n",
    "    \"BIOMARKER_STATUS\",\n",
    "    \"TREATMENT_ARM\",\n",
    "    \"COHORT\"\n",
    "]\n",
    "\n",
    "TARGET = \"IS_RESPONDER\"  # Binary classification: responder vs non-responder\n",
    "\n",
    "print(f\"Numeric features: {len(NUMERIC_FEATURES)}\")\n",
    "print(f\"Categorical features: {len(CATEGORICAL_FEATURES)}\")\n",
    "print(f\"Target: {TARGET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "build-pipeline",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.674585Z",
     "iopub.status.busy": "2026-01-20T00:17:48.674459Z",
     "iopub.status.idle": "2026-01-20T00:17:48.693006Z",
     "shell.execute_reply": "2026-01-20T00:17:48.692706Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Build Snowpark ML Pipeline\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# This runs entirely within Snowflake\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Preprocessing: Scale numeric, encode categorical\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m scaler = \u001b[43mStandardScaler\u001b[49m(\n\u001b[32m      6\u001b[39m     input_cols=NUMERIC_FEATURES,\n\u001b[32m      7\u001b[39m     output_cols=[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_SCALED\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m NUMERIC_FEATURES]\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m encoder = OneHotEncoder(\n\u001b[32m     11\u001b[39m     input_cols=CATEGORICAL_FEATURES,\n\u001b[32m     12\u001b[39m     output_cols=[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_ENCODED\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m CATEGORICAL_FEATURES],\n\u001b[32m     13\u001b[39m     drop_input_cols=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Model: XGBoost Classifier\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Build Snowpark ML Pipeline\n",
    "# This runs entirely within Snowflake\n",
    "\n",
    "# Preprocessing: Scale numeric, encode categorical\n",
    "scaler = StandardScaler(\n",
    "    input_cols=NUMERIC_FEATURES,\n",
    "    output_cols=[f\"{c}_SCALED\" for c in NUMERIC_FEATURES]\n",
    ")\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    input_cols=CATEGORICAL_FEATURES,\n",
    "    output_cols=[f\"{c}_ENCODED\" for c in CATEGORICAL_FEATURES],\n",
    "    drop_input_cols=True\n",
    ")\n",
    "\n",
    "# Model: XGBoost Classifier\n",
    "model = XGBClassifier(\n",
    "    input_cols=[f\"{c}_SCALED\" for c in NUMERIC_FEATURES] + \n",
    "               [f\"{c}_ENCODED\" for c in CATEGORICAL_FEATURES],\n",
    "    label_cols=[TARGET],\n",
    "    output_cols=[\"PREDICTION\"],\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Assemble pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"scaler\", scaler),\n",
    "    (\"encoder\", encoder),\n",
    "    (\"classifier\", model)\n",
    "])\n",
    "\n",
    "print(\"✓ ML Pipeline defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "train-model",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.694587Z",
     "iopub.status.busy": "2026-01-20T00:17:48.694503Z",
     "iopub.status.idle": "2026-01-20T00:17:48.709277Z",
     "shell.execute_reply": "2026-01-20T00:17:48.708926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model... (this runs on Snowflake compute)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# All computation happens in Snowflake warehouse\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining model... (this runs on Snowflake compute)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mpipeline\u001b[49m.fit(train_df)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ Model trained\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# All computation happens in Snowflake warehouse\n",
    "\n",
    "print(\"Training model... (this runs on Snowflake compute)\")\n",
    "pipeline.fit(train_df)\n",
    "print(\"✓ Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "evaluate-model",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.711106Z",
     "iopub.status.busy": "2026-01-20T00:17:48.710955Z",
     "iopub.status.idle": "2026-01-20T00:17:48.728179Z",
     "shell.execute_reply": "2026-01-20T00:17:48.727863Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Evaluate on validation set\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m val_predictions = \u001b[43mpipeline\u001b[49m.predict(val_df)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[32m      5\u001b[39m val_pdf = val_predictions.select(TARGET, \u001b[33m\"\u001b[39m\u001b[33mPREDICTION\u001b[39m\u001b[33m\"\u001b[39m).to_pandas()\n",
      "\u001b[31mNameError\u001b[39m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "val_predictions = pipeline.predict(val_df)\n",
    "\n",
    "# Calculate metrics\n",
    "val_pdf = val_predictions.select(TARGET, \"PREDICTION\").to_pandas()\n",
    "\n",
    "accuracy = accuracy_score(val_pdf[TARGET], val_pdf[\"PREDICTION\"])\n",
    "precision = precision_score(val_pdf[TARGET], val_pdf[\"PREDICTION\"])\n",
    "recall = recall_score(val_pdf[TARGET], val_pdf[\"PREDICTION\"])\n",
    "f1 = f1_score(val_pdf[TARGET], val_pdf[\"PREDICTION\"])\n",
    "\n",
    "print(\"=== Validation Metrics ===\")\n",
    "print(f\"Accuracy:  {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1 Score:  {f1:.3f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(val_pdf[TARGET], val_pdf[\"PREDICTION\"])\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"  TN={cm[0][0]}, FP={cm[0][1]}\")\n",
    "print(f\"  FN={cm[1][0]}, TP={cm[1][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registry-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Snowflake Model Registry\n",
    "\n",
    "Register the trained model in the **native Snowflake Model Registry**.\n",
    "\n",
    "Capabilities:\n",
    "- Version control with semantic versioning\n",
    "- Aliases for lifecycle stages (dev, staging, production)\n",
    "- Metrics tracking\n",
    "- Role-based access control\n",
    "- Automatic lineage to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "init-registry",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.729832Z",
     "iopub.status.busy": "2026-01-20T00:17:48.729737Z",
     "iopub.status.idle": "2026-01-20T00:17:48.742009Z",
     "shell.execute_reply": "2026-01-20T00:17:48.741704Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize Model Registry\u001b[39;00m\n\u001b[32m      2\u001b[39m registry = Registry(\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     session=\u001b[43msession\u001b[49m,\n\u001b[32m      4\u001b[39m     database_name=\u001b[33m\"\u001b[39m\u001b[33mLIFEARC_POC\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     schema_name=\u001b[33m\"\u001b[39m\u001b[33mML_DEMO\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ Model Registry initialized\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'session' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize Model Registry\n",
    "registry = Registry(\n",
    "    session=session,\n",
    "    database_name=\"LIFEARC_POC\",\n",
    "    schema_name=\"ML_DEMO\"\n",
    ")\n",
    "\n",
    "print(\"✓ Model Registry initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "log-model",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.743461Z",
     "iopub.status.busy": "2026-01-20T00:17:48.743376Z",
     "iopub.status.idle": "2026-01-20T00:17:48.760509Z",
     "shell.execute_reply": "2026-01-20T00:17:48.760088Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'registry' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Log model to registry with metrics\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model_version = \u001b[43mregistry\u001b[49m.log_model(\n\u001b[32m      3\u001b[39m     model=pipeline,\n\u001b[32m      4\u001b[39m     model_name=\u001b[33m\"\u001b[39m\u001b[33mCLINICAL_RESPONSE_PREDICTOR\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     version_name=\u001b[33m\"\u001b[39m\u001b[33mV1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     metrics={\n\u001b[32m      7\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(accuracy),\n\u001b[32m      8\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(precision),\n\u001b[32m      9\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(recall),\n\u001b[32m     10\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mf1_score\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(f1),\n\u001b[32m     11\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtraining_rows\u001b[39m\u001b[33m\"\u001b[39m: train_df.count(),\n\u001b[32m     12\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mvalidation_rows\u001b[39m\u001b[33m\"\u001b[39m: val_df.count()\n\u001b[32m     13\u001b[39m     },\n\u001b[32m     14\u001b[39m     comment=\u001b[33m\"\u001b[39m\u001b[33mXGBoost classifier for predicting clinical trial response\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ Model logged: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_version.model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_version.version_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'registry' is not defined"
     ]
    }
   ],
   "source": [
    "# Log model to registry with metrics\n",
    "model_version = registry.log_model(\n",
    "    model=pipeline,\n",
    "    model_name=\"CLINICAL_RESPONSE_PREDICTOR\",\n",
    "    version_name=\"V1\",\n",
    "    metrics={\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"precision\": float(precision),\n",
    "        \"recall\": float(recall),\n",
    "        \"f1_score\": float(f1),\n",
    "        \"training_rows\": train_df.count(),\n",
    "        \"validation_rows\": val_df.count()\n",
    "    },\n",
    "    comment=\"XGBoost classifier for predicting clinical trial response\"\n",
    ")\n",
    "\n",
    "print(f\"✓ Model logged: {model_version.model_name} version {model_version.version_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "set-alias",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.762077Z",
     "iopub.status.busy": "2026-01-20T00:17:48.761994Z",
     "iopub.status.idle": "2026-01-20T00:17:48.775046Z",
     "shell.execute_reply": "2026-01-20T00:17:48.774768Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_version' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Set alias for lifecycle management\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# This allows production code to always call 'production' version\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mmodel_version\u001b[49m.set_alias(\u001b[33m\"\u001b[39m\u001b[33mdevelopment\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ Alias \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdevelopment\u001b[39m\u001b[33m'\u001b[39m\u001b[33m set\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# After validation, promote to production:\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# model_version.set_alias(\"production\")\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'model_version' is not defined"
     ]
    }
   ],
   "source": [
    "# Set alias for lifecycle management\n",
    "# This allows production code to always call 'production' version\n",
    "\n",
    "model_version.set_alias(\"development\")\n",
    "print(\"✓ Alias 'development' set\")\n",
    "\n",
    "# After validation, promote to production:\n",
    "# model_version.set_alias(\"production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "list-models",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.776440Z",
     "iopub.status.busy": "2026-01-20T00:17:48.776340Z",
     "iopub.status.idle": "2026-01-20T00:17:48.790559Z",
     "shell.execute_reply": "2026-01-20T00:17:48.790152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Registry Contents ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'registry' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# List all models in registry\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Model Registry Contents ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mregistry\u001b[49m.show_models()\n",
      "\u001b[31mNameError\u001b[39m: name 'registry' is not defined"
     ]
    }
   ],
   "source": [
    "# List all models in registry\n",
    "print(\"=== Model Registry Contents ===\")\n",
    "registry.show_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "model-info",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.792372Z",
     "iopub.status.busy": "2026-01-20T00:17:48.792240Z",
     "iopub.status.idle": "2026-01-20T00:17:48.807074Z",
     "shell.execute_reply": "2026-01-20T00:17:48.806768Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'registry' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Get detailed model information\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mregistry\u001b[49m.get_model(\u001b[33m\"\u001b[39m\u001b[33mCLINICAL_RESPONSE_PREDICTOR\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mVersions:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'registry' is not defined"
     ]
    }
   ],
   "source": [
    "# Get detailed model information\n",
    "model = registry.get_model(\"CLINICAL_RESPONSE_PREDICTOR\")\n",
    "print(f\"Model: {model.name}\")\n",
    "print(f\"\\nVersions:\")\n",
    "for version in model.versions():\n",
    "    print(f\"  - {version.version_name}\")\n",
    "    print(f\"    Metrics: {version.get_metric('accuracy'):.3f} accuracy\")\n",
    "    print(f\"    Aliases: {version.list_aliases()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Model Inference\n",
    "\n",
    "Deploy the model for batch and real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "batch-inference",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.808566Z",
     "iopub.status.busy": "2026-01-20T00:17:48.808487Z",
     "iopub.status.idle": "2026-01-20T00:17:48.823586Z",
     "shell.execute_reply": "2026-01-20T00:17:48.823236Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'registry' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Batch inference on test set\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Retrieve model from registry and run predictions\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model_ref = \u001b[43mregistry\u001b[49m.get_model(\u001b[33m\"\u001b[39m\u001b[33mCLINICAL_RESPONSE_PREDICTOR\u001b[39m\u001b[33m\"\u001b[39m).version(\u001b[33m\"\u001b[39m\u001b[33mV1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Run inference\u001b[39;00m\n\u001b[32m      7\u001b[39m test_predictions = model_ref.run(test_df, function_name=\u001b[33m\"\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'registry' is not defined"
     ]
    }
   ],
   "source": [
    "# Batch inference on test set\n",
    "# Retrieve model from registry and run predictions\n",
    "\n",
    "model_ref = registry.get_model(\"CLINICAL_RESPONSE_PREDICTOR\").version(\"V1\")\n",
    "\n",
    "# Run inference\n",
    "test_predictions = model_ref.run(test_df, function_name=\"predict\")\n",
    "\n",
    "print(\"=== Test Set Predictions ===\")\n",
    "test_predictions.select(\n",
    "    \"RESULT_ID\", \n",
    "    \"PATIENT_ID\", \n",
    "    TARGET, \n",
    "    \"PREDICTION\"\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "test-metrics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.825059Z",
     "iopub.status.busy": "2026-01-20T00:17:48.824973Z",
     "iopub.status.idle": "2026-01-20T00:17:48.840736Z",
     "shell.execute_reply": "2026-01-20T00:17:48.840452Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Final test metrics\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m test_pdf = \u001b[43mtest_predictions\u001b[49m.select(TARGET, \u001b[33m\"\u001b[39m\u001b[33mPREDICTION\u001b[39m\u001b[33m\"\u001b[39m).to_pandas()\n\u001b[32m      4\u001b[39m test_accuracy = accuracy_score(test_pdf[TARGET], test_pdf[\u001b[33m\"\u001b[39m\u001b[33mPREDICTION\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      5\u001b[39m test_precision = precision_score(test_pdf[TARGET], test_pdf[\u001b[33m\"\u001b[39m\u001b[33mPREDICTION\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'test_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# Final test metrics\n",
    "test_pdf = test_predictions.select(TARGET, \"PREDICTION\").to_pandas()\n",
    "\n",
    "test_accuracy = accuracy_score(test_pdf[TARGET], test_pdf[\"PREDICTION\"])\n",
    "test_precision = precision_score(test_pdf[TARGET], test_pdf[\"PREDICTION\"])\n",
    "test_recall = recall_score(test_pdf[TARGET], test_pdf[\"PREDICTION\"])\n",
    "test_f1 = f1_score(test_pdf[TARGET], test_pdf[\"PREDICTION\"])\n",
    "\n",
    "print(\"=== Test Set Metrics (Holdout) ===\")\n",
    "print(f\"Accuracy:  {test_accuracy:.3f}\")\n",
    "print(f\"Precision: {test_precision:.3f}\")\n",
    "print(f\"Recall:    {test_recall:.3f}\")\n",
    "print(f\"F1 Score:  {test_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "sql-inference",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.842240Z",
     "iopub.status.busy": "2026-01-20T00:17:48.842132Z",
     "iopub.status.idle": "2026-01-20T00:17:48.844123Z",
     "shell.execute_reply": "2026-01-20T00:17:48.843851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Inference Pattern:\n",
      "\n",
      "-- Call model directly from SQL\n",
      "WITH patient_features AS (\n",
      "    SELECT * FROM LIFEARC_POC.ML_FEATURE_STORE.PATIENT_CLINICAL_FEATURES$V1\n",
      "),\n",
      "trial_features AS (\n",
      "    SELECT * FROM LIFEARC_POC.ML_FEATURE_STORE.TRIAL_AGGREGATE_FEATURES$V1\n",
      ")\n",
      "SELECT \n",
      "    p.PATIENT_ID,\n",
      "    LIFEARC_POC.ML_DEMO.CLINICAL_RESPONSE_PREDICTOR!PREDICT(\n",
      "        OBJECT_CONSTRUCT(*)\n",
      "    ) AS PREDICTION\n",
      "FROM patient_features p\n",
      "JOIN trial_features t ON p.TRIAL_ID = t.TRIAL_ID\n",
      "LIMIT 10;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL-based inference (for production use)\n",
    "# This is how downstream systems would call the model\n",
    "\n",
    "sql_inference_example = \"\"\"\n",
    "-- Call model directly from SQL\n",
    "WITH patient_features AS (\n",
    "    SELECT * FROM LIFEARC_POC.ML_FEATURE_STORE.PATIENT_CLINICAL_FEATURES$V1\n",
    "),\n",
    "trial_features AS (\n",
    "    SELECT * FROM LIFEARC_POC.ML_FEATURE_STORE.TRIAL_AGGREGATE_FEATURES$V1\n",
    ")\n",
    "SELECT \n",
    "    p.PATIENT_ID,\n",
    "    LIFEARC_POC.ML_DEMO.CLINICAL_RESPONSE_PREDICTOR!PREDICT(\n",
    "        OBJECT_CONSTRUCT(*)\n",
    "    ) AS PREDICTION\n",
    "FROM patient_features p\n",
    "JOIN trial_features t ON p.TRIAL_ID = t.TRIAL_ID\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "print(\"SQL Inference Pattern:\")\n",
    "print(sql_inference_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monitoring-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: Model Monitoring & Observability\n",
    "\n",
    "Set up monitoring for:\n",
    "- Prediction drift\n",
    "- Feature distribution changes\n",
    "- Performance degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "create-monitoring-table",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.845596Z",
     "iopub.status.busy": "2026-01-20T00:17:48.845512Z",
     "iopub.status.idle": "2026-01-20T00:17:48.859511Z",
     "shell.execute_reply": "2026-01-20T00:17:48.859244Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create monitoring table for tracking predictions over time\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msession\u001b[49m.sql(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33m    CREATE TABLE IF NOT EXISTS LIFEARC_POC.ML_DEMO.MODEL_MONITORING (\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33m        MONITORING_ID VARCHAR DEFAULT UUID_STRING(),\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33m        MODEL_NAME VARCHAR,\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33m        MODEL_VERSION VARCHAR,\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33m        MONITORING_DATE DATE,\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m        TOTAL_PREDICTIONS INT,\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m        POSITIVE_PREDICTIONS INT,\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33m        NEGATIVE_PREDICTIONS INT,\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m        POSITIVE_RATE FLOAT,\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[33m        AVG_CONFIDENCE FLOAT,\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[33m        FEATURE_STATS VARIANT,\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33m        CREATED_AT TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m    )\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m\"\"\"\u001b[39m).collect()\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ Monitoring table created\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'session' is not defined"
     ]
    }
   ],
   "source": [
    "# Create monitoring table for tracking predictions over time\n",
    "session.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS LIFEARC_POC.ML_DEMO.MODEL_MONITORING (\n",
    "        MONITORING_ID VARCHAR DEFAULT UUID_STRING(),\n",
    "        MODEL_NAME VARCHAR,\n",
    "        MODEL_VERSION VARCHAR,\n",
    "        MONITORING_DATE DATE,\n",
    "        TOTAL_PREDICTIONS INT,\n",
    "        POSITIVE_PREDICTIONS INT,\n",
    "        NEGATIVE_PREDICTIONS INT,\n",
    "        POSITIVE_RATE FLOAT,\n",
    "        AVG_CONFIDENCE FLOAT,\n",
    "        FEATURE_STATS VARIANT,\n",
    "        CREATED_AT TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()\n",
    "    )\n",
    "\"\"\").collect()\n",
    "\n",
    "print(\"✓ Monitoring table created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "log-predictions",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.861047Z",
     "iopub.status.busy": "2026-01-20T00:17:48.860954Z",
     "iopub.status.idle": "2026-01-20T00:17:48.876718Z",
     "shell.execute_reply": "2026-01-20T00:17:48.876346Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Log today's prediction statistics\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m prediction_stats = \u001b[43mtest_predictions\u001b[49m.agg(\n\u001b[32m      3\u001b[39m     F.count(\u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m).alias(\u001b[33m\"\u001b[39m\u001b[33mTOTAL\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      4\u001b[39m     F.sum(F.when(F.col(\u001b[33m\"\u001b[39m\u001b[33mPREDICTION\u001b[39m\u001b[33m\"\u001b[39m) == \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m).otherwise(\u001b[32m0\u001b[39m)).alias(\u001b[33m\"\u001b[39m\u001b[33mPOSITIVE\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      5\u001b[39m     F.sum(F.when(F.col(\u001b[33m\"\u001b[39m\u001b[33mPREDICTION\u001b[39m\u001b[33m\"\u001b[39m) == \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m).otherwise(\u001b[32m0\u001b[39m)).alias(\u001b[33m\"\u001b[39m\u001b[33mNEGATIVE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m ).collect()[\u001b[32m0\u001b[39m]\n\u001b[32m      8\u001b[39m session.sql(\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m    INSERT INTO LIFEARC_POC.ML_DEMO.MODEL_MONITORING \u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33m    (MODEL_NAME, MODEL_VERSION, MONITORING_DATE, TOTAL_PREDICTIONS, \u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \u001b[33m    )\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[33m\"\"\"\u001b[39m).collect()\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ Prediction statistics logged\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'test_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# Log today's prediction statistics\n",
    "prediction_stats = test_predictions.agg(\n",
    "    F.count(\"*\").alias(\"TOTAL\"),\n",
    "    F.sum(F.when(F.col(\"PREDICTION\") == 1, 1).otherwise(0)).alias(\"POSITIVE\"),\n",
    "    F.sum(F.when(F.col(\"PREDICTION\") == 0, 1).otherwise(0)).alias(\"NEGATIVE\")\n",
    ").collect()[0]\n",
    "\n",
    "session.sql(f\"\"\"\n",
    "    INSERT INTO LIFEARC_POC.ML_DEMO.MODEL_MONITORING \n",
    "    (MODEL_NAME, MODEL_VERSION, MONITORING_DATE, TOTAL_PREDICTIONS, \n",
    "     POSITIVE_PREDICTIONS, NEGATIVE_PREDICTIONS, POSITIVE_RATE)\n",
    "    VALUES (\n",
    "        'CLINICAL_RESPONSE_PREDICTOR',\n",
    "        'V1',\n",
    "        CURRENT_DATE(),\n",
    "        {prediction_stats['TOTAL']},\n",
    "        {prediction_stats['POSITIVE']},\n",
    "        {prediction_stats['NEGATIVE']},\n",
    "        {prediction_stats['POSITIVE'] / prediction_stats['TOTAL']:.4f}\n",
    "    )\n",
    "\"\"\").collect()\n",
    "\n",
    "print(\"✓ Prediction statistics logged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "drift-detection-sql",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.878473Z",
     "iopub.status.busy": "2026-01-20T00:17:48.878369Z",
     "iopub.status.idle": "2026-01-20T00:17:48.880552Z",
     "shell.execute_reply": "2026-01-20T00:17:48.880280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift Detection Query:\n",
      "\n",
      "-- Detect prediction drift\n",
      "WITH baseline AS (\n",
      "    SELECT AVG(POSITIVE_RATE) AS baseline_rate\n",
      "    FROM LIFEARC_POC.ML_DEMO.MODEL_MONITORING\n",
      "    WHERE MODEL_NAME = 'CLINICAL_RESPONSE_PREDICTOR'\n",
      "      AND MONITORING_DATE < CURRENT_DATE() - 7\n",
      "),\n",
      "current AS (\n",
      "    SELECT AVG(POSITIVE_RATE) AS current_rate\n",
      "    FROM LIFEARC_POC.ML_DEMO.MODEL_MONITORING\n",
      "    WHERE MODEL_NAME = 'CLINICAL_RESPONSE_PREDICTOR'\n",
      "      AND MONITORING_DATE >= CURRENT_DATE() - 7\n",
      ")\n",
      "SELECT \n",
      "    b.baseline_rate,\n",
      "    c.current_rate,\n",
      "    ABS(c.current_rate - b.baseline_rate) AS drift,\n",
      "    CASE \n",
      "        WHEN ABS(c.current_rate - b.baseline_rate) > 0.1 THEN 'ALERT: Significant drift detected'\n",
      "        WHEN ABS(c.current_rate - b.baseline_rate) > 0.05 THEN 'WARNING: Moderate drift'\n",
      "        ELSE 'OK: Within normal range'\n",
      "    END AS status\n",
      "FROM baseline b, current c;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drift detection query\n",
    "# Compare current predictions to historical baseline\n",
    "\n",
    "drift_query = \"\"\"\n",
    "-- Detect prediction drift\n",
    "WITH baseline AS (\n",
    "    SELECT AVG(POSITIVE_RATE) AS baseline_rate\n",
    "    FROM LIFEARC_POC.ML_DEMO.MODEL_MONITORING\n",
    "    WHERE MODEL_NAME = 'CLINICAL_RESPONSE_PREDICTOR'\n",
    "      AND MONITORING_DATE < CURRENT_DATE() - 7\n",
    "),\n",
    "current AS (\n",
    "    SELECT AVG(POSITIVE_RATE) AS current_rate\n",
    "    FROM LIFEARC_POC.ML_DEMO.MODEL_MONITORING\n",
    "    WHERE MODEL_NAME = 'CLINICAL_RESPONSE_PREDICTOR'\n",
    "      AND MONITORING_DATE >= CURRENT_DATE() - 7\n",
    ")\n",
    "SELECT \n",
    "    b.baseline_rate,\n",
    "    c.current_rate,\n",
    "    ABS(c.current_rate - b.baseline_rate) AS drift,\n",
    "    CASE \n",
    "        WHEN ABS(c.current_rate - b.baseline_rate) > 0.1 THEN 'ALERT: Significant drift detected'\n",
    "        WHEN ABS(c.current_rate - b.baseline_rate) > 0.05 THEN 'WARNING: Moderate drift'\n",
    "        ELSE 'OK: Within normal range'\n",
    "    END AS status\n",
    "FROM baseline b, current c;\n",
    "\"\"\"\n",
    "\n",
    "print(\"Drift Detection Query:\")\n",
    "print(drift_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "scheduled-monitoring",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.881997Z",
     "iopub.status.busy": "2026-01-20T00:17:48.881904Z",
     "iopub.status.idle": "2026-01-20T00:17:48.883740Z",
     "shell.execute_reply": "2026-01-20T00:17:48.883484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled Monitoring Task:\n",
      "\n",
      "-- Create scheduled monitoring task\n",
      "CREATE OR REPLACE TASK LIFEARC_POC.ML_DEMO.MONITOR_MODEL_PREDICTIONS\n",
      "    WAREHOUSE = COMPUTE_WH\n",
      "    SCHEDULE = 'USING CRON 0 8 * * * UTC'  -- Daily at 8 AM UTC\n",
      "AS\n",
      "CALL LIFEARC_POC.ML_DEMO.LOG_PREDICTION_STATS();\n",
      "\n",
      "-- To enable:\n",
      "-- ALTER TASK LIFEARC_POC.ML_DEMO.MONITOR_MODEL_PREDICTIONS RESUME;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create scheduled task for continuous monitoring\n",
    "monitoring_task_sql = \"\"\"\n",
    "-- Create scheduled monitoring task\n",
    "CREATE OR REPLACE TASK LIFEARC_POC.ML_DEMO.MONITOR_MODEL_PREDICTIONS\n",
    "    WAREHOUSE = COMPUTE_WH\n",
    "    SCHEDULE = 'USING CRON 0 8 * * * UTC'  -- Daily at 8 AM UTC\n",
    "AS\n",
    "CALL LIFEARC_POC.ML_DEMO.LOG_PREDICTION_STATS();\n",
    "\n",
    "-- To enable:\n",
    "-- ALTER TASK LIFEARC_POC.ML_DEMO.MONITOR_MODEL_PREDICTIONS RESUME;\n",
    "\"\"\"\n",
    "\n",
    "print(\"Scheduled Monitoring Task:\")\n",
    "print(monitoring_task_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lineage-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 9: ML Lineage\n",
    "\n",
    "Snowflake ML automatically tracks lineage from:\n",
    "- Source data → Features → Training Dataset → Model\n",
    "\n",
    "This is critical for:\n",
    "- Regulatory compliance (21 CFR Part 11)\n",
    "- Reproducibility\n",
    "- Debugging production issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "view-lineage",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.885072Z",
     "iopub.status.busy": "2026-01-20T00:17:48.884958Z",
     "iopub.status.idle": "2026-01-20T00:17:48.886873Z",
     "shell.execute_reply": "2026-01-20T00:17:48.886611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lineage Query:\n",
      "\n",
      "-- View model lineage\n",
      "SELECT \n",
      "    OBJECT_NAME,\n",
      "    OBJECT_DATABASE,\n",
      "    OBJECT_SCHEMA,\n",
      "    OBJECT_TYPE,\n",
      "    UPSTREAM_OBJECT_NAME,\n",
      "    UPSTREAM_OBJECT_TYPE\n",
      "FROM TABLE(INFORMATION_SCHEMA.OBJECT_DEPENDENCIES(\n",
      "    OBJECT_NAME => 'CLINICAL_RESPONSE_PREDICTOR',\n",
      "    OBJECT_TYPE => 'MODEL'\n",
      "));\n",
      "\n",
      "\n",
      "Tip: View lineage graph in Snowsight > Data > ML_DEMO > Models > CLINICAL_RESPONSE_PREDICTOR\n"
     ]
    }
   ],
   "source": [
    "# Query lineage information\n",
    "lineage_query = \"\"\"\n",
    "-- View model lineage\n",
    "SELECT \n",
    "    OBJECT_NAME,\n",
    "    OBJECT_DATABASE,\n",
    "    OBJECT_SCHEMA,\n",
    "    OBJECT_TYPE,\n",
    "    UPSTREAM_OBJECT_NAME,\n",
    "    UPSTREAM_OBJECT_TYPE\n",
    "FROM TABLE(INFORMATION_SCHEMA.OBJECT_DEPENDENCIES(\n",
    "    OBJECT_NAME => 'CLINICAL_RESPONSE_PREDICTOR',\n",
    "    OBJECT_TYPE => 'MODEL'\n",
    "));\n",
    "\"\"\"\n",
    "\n",
    "print(\"Lineage Query:\")\n",
    "print(lineage_query)\n",
    "\n",
    "# In Snowsight, you can also visualize lineage graphically\n",
    "print(\"\\nTip: View lineage graph in Snowsight > Data > ML_DEMO > Models > CLINICAL_RESPONSE_PREDICTOR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: Complete ML Lifecycle in Snowflake\n",
    "\n",
    "This notebook demonstrated end-to-end ML using **native Snowflake capabilities**:\n",
    "\n",
    "| Stage | What We Built | Snowflake Feature |\n",
    "|-------|---------------|-------------------|\n",
    "| 1. Discovery | Explored clinical trial data | Snowpark DataFrames |\n",
    "| 2. Features | Patient & Trial feature views | **Snowflake Feature Store** |\n",
    "| 3. Training | XGBoost classification pipeline | Snowpark ML |\n",
    "| 4. Registry | Versioned model with metrics | **Snowflake Model Registry** |\n",
    "| 5. Inference | Batch predictions via SQL | Model Registry |\n",
    "| 6. Monitoring | Drift detection | ML Observability |\n",
    "| 7. Lineage | Source-to-model traceability | **ML Lineage** |\n",
    "\n",
    "### Objects Created\n",
    "\n",
    "```\n",
    "LIFEARC_POC.ML_FEATURE_STORE/\n",
    "├── PATIENT entity\n",
    "├── TRIAL entity\n",
    "├── PATIENT_CLINICAL_FEATURES (Feature View)\n",
    "└── TRIAL_AGGREGATE_FEATURES (Feature View)\n",
    "\n",
    "LIFEARC_POC.ML_DEMO/\n",
    "├── CLINICAL_RESPONSE_PREDICTOR (Model)\n",
    "│   └── V1 (Version, alias: development)\n",
    "└── MODEL_MONITORING (Table)\n",
    "```\n",
    "\n",
    "### Why This Matters for Life Sciences\n",
    "\n",
    "1. **Regulatory Compliance**: Full lineage from source to prediction\n",
    "2. **Data Governance**: PHI never leaves Snowflake\n",
    "3. **Reproducibility**: Feature Store ensures consistent features\n",
    "4. **Auditability**: Model Registry tracks all versions\n",
    "5. **Operationalization**: SQL-based inference for production systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cleanup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T00:17:48.888265Z",
     "iopub.status.busy": "2026-01-20T00:17:48.888154Z",
     "iopub.status.idle": "2026-01-20T00:17:48.889802Z",
     "shell.execute_reply": "2026-01-20T00:17:48.889550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Notebook complete\n"
     ]
    }
   ],
   "source": [
    "# Close session if running locally\n",
    "# session.close()\n",
    "print(\"\\n✓ Notebook complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
